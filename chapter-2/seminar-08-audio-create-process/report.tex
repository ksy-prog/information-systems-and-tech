% реферат: «Технологии создания и обработки аудио»
% ИСПРАВЛЕННАЯ ВЕРСИЯ - устранены конфликты пакетов и дубликаты

\documentclass{SibFU-docs} % нужно скачать файл в корне репозитория "SibFU-docs.cls"!!!
\usepackage{newtxtext}
\usepackage{newtxmath}

% класс уже загрузил inputenc, fontenc, babel, csquotes, biblatex!!!

% графика и математика
\usepackage{graphicx}
\usepackage{amsmath}

% листинги кода
\usepackage{listings}
\lstset{basicstyle=\ttfamily\small,breaklines=true,frame=single}

% таблицы
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{array}

% подписи и float-окружения
\usepackage{caption}
\usepackage{subcaption}
\usepackage{float}

% микротипография
\usepackage[expansion=false]{microtype}

% гиперссылки
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=black,
    citecolor=blue,
    urlcolor=blue,
    pdfauthor={Студенты ГФ25-02Б},
    pdftitle={Технологии создания и обработки аудио}
}

% ===== библиография =====
% класс уже подключил biblatex, просто добавляем источник:
\addbibresource{report.bib}

% ===== условные определения шрифтовых команд =====
\makeatletter
\@ifundefined{setmainfont}{\newcommand{\setmainfont}[2][]{}}{}
\@ifundefined{setsansfont}{\newcommand{\setsansfont}[2][]{}}{}
\@ifundefined{setmonofont}{\newcommand{\setmonofont}[2][]{}}{}
\makeatother

\begin{document}

% ----------------- титульный лист -----------------
\makecovertitle%
{Гуманитарный институт}%
{Кафедра прикладной информатики в искусстве и интерактивных медиа}%
{ТЕХНОЛОГИИ СОЗДАНИЯ И ОБРАБОТКИ АУДИО}%
{ГФ25-02Б}%

% ----------------- аннотация -----------------
\begin{abstract}
Данный реферат представляет собой систематизированный и развернутый обзор современных технологий создания, кодирования, сжатия, передачи, хранения и обработки аудиосигналов. В работе детально рассмотрены фундаментальные принципы цифрового представления звука, включая математические основы дискретизации и квантования, методы кодирования и передачи с анализом современных протоколов, комплексный сравнительный анализ методов сжатия с потерями и без потерь с учетом психоакустических моделей, подробный обзор основных форматов и кодеков с техническими характеристиками, практики редактирования и мастеринга в современных DAW с описанием конкретных техник обработки, а также перспективы развития пространственного и объемного звука с анализом emerging technologies. Каждый раздел основан на научных и технических источниках из списка литературы \cite{smith1997dsp,pohlmann2011principles,shannon1948mathematical,pan1995,bosi2002,flac2024} и содержит подробные технические объяснения, математические выкладки и практические рекомендации.
\end{abstract}

\tableofcontents
\newpage

% ----------------- введение -----------------
\section{Введение}
Звук в цифровой форме представляет собой фундаментальный компонент современной медиасреды, пронизывающий все аспекты цифровой культуры: от музыкальной индустрии и подкастинга до кинопроизводства, видеоигр и голосовых сервисов. Для обеспечения высокого качества воспроизведения, эффективной передачи по каналам связи с ограниченной пропускной способностью и надежного долговременного хранения аудиоконтента требуется сложный набор методик и технологий — от физической записи и корректной оцифровки до продвинутых методов кодирования, компрессии и постобработки. 

В настоящем реферате мы осуществляем систематизацию и детальное объяснение основных положений цифровой аудиотехнологии, опираясь на классические источники и современные стандарты \cite{watkinson2012art,roadstocompression,smith1997dsp}. Особое внимание уделяется математическим основам процессов преобразования звука, техническим особенностям реализации различных кодеков и практическим аспектам применения рассмотренных технологий в реальных производственных цепочках.

Детализированная структура работы включает следующие основные разделы:
\begin{enumerate}
    \item \textbf{Основы представления звука} — детальный разбор процессов дискретизации, квантования и кодирования с математическим обоснованием, включая теорему Котельникова-Найквиста-Шеннона, анализ ошибок квантования и шумов digitization
    \item \textbf{Кодирование и передача} — технологии АЦП/ЦАП, протоколы потоковой передачи, беспроводные решения и цифровые интерфейсы
    \item \textbf{Сжатие аудиоданных} — подробное сравнение методов lossless и lossy компрессии, психоакустические модели, практические рекомендации по выбору битрейта
    \item \textbf{Форматы и кодеки} — детальный обзор MP3, AAC, Vorbis, Opus, FLAC, ALAC и других форматов с техническими спецификациями
    \item \textbf{Редактирование и обработка} — практика работы в DAW, техники редактирования, мастеринг и плагины
    \item \textbf{Перспективы развития} — анализ emerging technologies пространственного звука, объектного аудио, бинаурального рендеринга и интеллектуальной обработки
\end{enumerate}

Каждый раздел содержит развернутое изложение с примерами, математическими формулами, сравнительными таблицами и ссылками на использованную литературу из \texttt{report.bib}.

% ----------------- вопрос 1 -----------------
\section{Основы представления звука в цифровых системах}
\label{sec:fundamentals}
Этот раздел основан на классических источниках по цифровой обработке сигналов \cite{smith1997dsp,pohlmann2011principles}.

\subsection{Аналоговый сигнал и его параметры}
Звук представляет собой механические колебания упругих сред, которые могут быть описаны тремя фундаментальными параметрами: \emph{амплитудой} (интенсивность колебаний, определяющая громкость), \emph{частотой} (количество колебаний в единицу времени, определяющее высоту тона) и \emph{фазой} (моментальное состояние колебательного процесса). В аналоговом представлении звуковой сигнал является непрерывной функцией времени $s(t)$, которая может принимать любые значения в определенном диапазоне.

Физическая природа звука определяется распространением продольных волн в упругой среде. Когда источник звука (например, колеблющаяся мембрана динамика или струна музыкального инструмента) совершает колебательное движение, он создает области сжатия и разрежения в окружающей среде. Эти области распространяются в пространстве со скоростью звука, которая в воздухе при нормальных условиях составляет приблизительно 343 м/с.

Амплитуда колебаний непосредственно связана с энергией волны и воспринимается человеческим слухом как громкость звука. Важно отметить, что восприятие громкости имеет логарифмический характер — увеличение физической интенсивности звука в 10 раз воспринимается как увеличение громкости примерно в 2 раза. Это свойство слуховой системы легло в основу логарифмической шкалы измерения уровня звукового давления в децибелах (дБ).

Частота определяет высоту тона звука и измеряется в герцах (Гц) — количестве полных колебаний в секунду. Человеческий слух способен воспринимать звуковые частоты в диапазоне приблизительно от 20 Гц до 20 кГц, хотя с возрастом верхняя граница значительно снижается. Музыкальные звуки обычно находятся в диапазоне от 27.5 Гц (нота A0 на фортепиано) до примерно 4.186 Гц (C8), хотя обертоны могут простираться значительно выше.

Фаза описывает положение точки в цикле колебаний в конкретный момент времени и измеряется в градусах (0°–360°) или радианах (0–$2\pi$). Хотя изолированная фаза одного звука не влияет на его восприятие, фазовые соотношения между несколькими звуками критически важны. Явление интерференции — конструктивной (усиление при синфазном сложении) или деструктивной (ослабление при противофазном сложении) — полностью определяется фазовыми соотношениями между компонентами сигнала.

Для перехода в цифровую среду требуется выполнение двух фундаментальных преобразований: \emph{дискретизации по времени} (sampling) и \emph{квантования по амплитуде} (quantization). Первая операция преобразует непрерывный сигнал в последовательность отсчетов, вторая — непрерывное множество возможных значений амплитуды в дискретное конечное множество. Эти два процесса составляют основу цифрового представления звука и определяют качество, точность и объем получающихся цифровых данных.

\subsection{Дискретизация и теорема Найквиста-Шеннона}
Процесс дискретизации заключается в получении значений непрерывного сигнала в дискретные моменты времени, обычно равноотстоящие друг от друга. Математически это может быть представлено как умножение исходного сигнала $s(t)$ на последовательность дельта-функций:
$$s_d(t) = s(t) \cdot \sum_{n=-\infty}^{\infty} \delta(t - nT_s)$$
где $T_s = 1/F_s$ — период дискретизации, $F_s$ — частота дискретизации.

Дискретизация представляет собой ключевой этап перехода от аналогового к цифровому представлению сигнала. В отличие от непрерывного сигнала, который существует во всех точках временной оси, дискретизированный сигнал представлен только в определенных, дискретных моментах времени. Интервал между последовательными отсчетами определяется периодом дискретизации $T_s$, а обратная величина — частота дискретизации $F_s$ — показывает, сколько отсчетов берется в единицу времени.

Фундаментальный вопрос, возникающий при дискретизации: насколько часто нужно брать отсчеты, чтобы иметь возможность точно восстановить исходный непрерывный сигнал? Ответ на этот вопрос дает \textbf{теорема Котельникова-Найквиста-Шеннона}, являющаяся одним из краеугольных камней теории цифровой обработки сигналов.

Теорема устанавливает фундаментальное условие для возможности точного восстановления сигнала: частота дискретизации $F_s$ должна быть как минимум в два раза больше максимальной частоты $F_{\max}$, присутствующей в спектре сигнала:
$$F_s > 2 F_{\max}$$

Величина $F_N = F_s/2$ называется \emph{частотой Найквиста} и представляет собой максимальную частоту, которая может быть корректно представлена при данной частоте дискретизации. Любые частотные компоненты сигнала, превышающие частоту Найквиста, будут неправильно интерпретированы после дискретизации.

Нарушение этого условия приводит к возникновению \emph{алиасинга} (наложения спектров) — серьезного искажения сигнала, при котором высокочастотные компоненты, превышающие частоту Найквиста, "отражаются" обратно в слышимый диапазон и воспринимаются как ложные низкочастотные компоненты \cite{shannon1948mathematical}. Например, если при частоте дискретизации 44.1 кГц (частота Найквиста 22.05 кГц) в сигнале присутствует компонента с частотой 25 кГц, она будет восприниматься как компонента с частотой $44.1 - 25 = 19.1$ кГц, создавая нежелательный артефакт.

Для предотвращения алиасинга перед дискретизацией обязательно применяется \emph{антиалиасинговый фильтр} (anti-aliasing filter) — аналоговый фильтр низких частот, который подавляет все частотные компоненты выше частоты Найквиста. Качество этого фильтра критически важно для общего качества оцифровки: он должен обеспечивать достаточно крутой спад АЧХ, чтобы эффективно подавлять нежелательные частоты, но при этом не вносить фазовых искажений в полезную полосу.

На практике применяются стандартизированные значения частоты дискретизации, каждое из которых имеет свою историю и область применения:

\begin{itemize}
    \item \textbf{44.1~кГц} — стандарт для аудио-CD, выбранный как компромисс между качеством и объемом данных. Историческая причина выбора именно этого значения связана с использованием видеомагнитофонов для цифровой записи звука в начале 1980-х годов. Эта частота обеспечивает воспроизведение частот до 22.05 кГц, что с небольшим запасом перекрывает диапазон человеческого слуха.
    
    \item \textbf{48~кГц} — стандарт для видеопроизводства и профессиональной аудиозаписи, принятый в цифровом телевидении и кинопроизводстве. Выбор этой частоты обусловлен её математическими свойствами (легко делится на частоты кадров видео) и обеспечивает несколько более широкую полосу воспроизведения.
    
    \item \textbf{88.2~кГц и 96~кГц} — удвоенные частоты базовых стандартов, используются для профессиональной записи и обработки. Дополнительная полоса пропускания используется не столько для расширения слышимого диапазона, сколько для упрощения требований к антиалиасинговым фильтрам и уменьшения их влияния на фазовую характеристику в слышимом диапазоне.
    
    \item \textbf{192~кГц} — высшая частота дискретизации в форматах high-resolution audio, применяется для архивирования и в случаях, когда планируется значительная последующая обработка сигнала. Практическая польза столь высокой частоты дискретизации для конечного прослушивания остается предметом дискуссий в профессиональном сообществе.
\end{itemize}

Выбор частоты дискретизации в конкретном проекте должен учитывать не только требования к качеству звука, но и объем данных, вычислительную нагрузку при обработке, совместимость с другими системами и стандартами.

\subsection{Квантование и битовая глубина}
Процесс квантования заключается в сопоставлении каждому отсчету сигнала одного из конечного числа уровней квантования. Если сигнал принимает значения в диапазоне $[-A, A]$, а используется $N$ бит для представления каждого отсчета, то число уровней квантования составляет $L = 2^N$, а шаг квантования:
$$\Delta = \frac{2A}{2^N}$$

После того как сигнал дискретизирован по времени, необходимо выполнить второе фундаментальное преобразование — квантование по амплитуде. В то время как дискретизация превращает непрерывную функцию времени в последовательность отсчетов, квантование преобразует непрерывное множество возможных значений амплитуды в дискретное, конечное множество разрешенных уровней.

Битовая глубина (bit depth) $N$ определяет количество бит, используемых для представления каждого отсчета, и непосредственно влияет на число доступных уровней квантования $L = 2^N$. Например, при 16-битном квантовании каждый отсчет может принимать одно из 65,536 различных значений, при 24-битном — одно из 16,777,216 значений.

Квантование неизбежно вносит ошибку — \emph{шум квантования} $e(n) = x(n) - Q[x(n)]$, где $Q[\cdot]$ — оператор квантования, $x(n)$ — истинное значение отсчета, а $Q[x(n)]$ — его квантованное представление. Эта ошибка не может быть устранена на этапе воспроизведения — она представляет собой необратимую потерю информации, вносимую в процессе аналого-цифрового преобразования.

При равномерном квантовании максимальная ошибка квантования составляет $\pm\Delta/2$, где $\Delta$ — шаг квантования. Если рассматривать ошибку квантования как случайную величину, равномерно распределенную в диапазоне $[-\Delta/2, \Delta/2]$, можно получить выражение для отношения сигнал-шум (SNR).

Для сигнала, занимающего весь динамический диапазон системы, отношение сигнал-шум составляет приблизительно:
$$\text{SNR} \approx 6.02N + 1.76 \text{ дБ}$$

Это фундаментальное соотношение показывает, что каждый дополнительный бит увеличивает SNR примерно на 6 дБ, что соответствует удвоению разрешения по амплитуде. Член 1.76 дБ связан с математическими свойствами синусоидального тестового сигнала и равномерного распределения ошибки квантования.

Практические значения SNR для различных битовых глубин:
\begin{itemize}
    \item \textbf{8 бит} — $\sim$50~дБ SNR. Это низкое качество, использовавшееся в ранних цифровых системах, телефонных приложениях и простых звуковых эффектах. Шум квантования явно слышим, особенно на тихих звуках или затуханиях.
    
    \item \textbf{16 бит} — $\sim$98~дБ SNR. Стандарт CD-качества, который оказался достаточным для подавляющего большинства применений. Динамический диапазон 96 дБ превышает возможности большинства акустических систем и условий прослушивания. Шум квантования становится слышимым только на очень тихих звуках при высокой громкости воспроизведения.
    
    \item \textbf{24 бит} — $\sim$146~дБ SNR. Профессиональное качество для студийной записи и обработки. Столь высокий динамический диапазон превосходит физические возможности человеческого слуха (примерно 120 дБ от порога слышимости до болевого порога) и обеспечивает значительный "запас прочности" для многократной обработки сигнала без накопления ошибок округления.
    
    \item \textbf{32 бит с плавающей точкой} — использование формата floating-point вместо integer устраняет необходимость беспокоиться о динамическом диапазоне и клиппинге на этапах промежуточной обработки. Внутренняя обработка в современных DAW обычно выполняется именно в 32-битном (или даже 64-битном) floating-point формате, что обеспечивает теоретически неограниченный динамический диапазон и исключительную точность вычислений.
\end{itemize}

Важно понимать, что шум квантования наиболее заметен на сигналах с низким уровнем. При записи с 16-битной разрядностью, если сигнал использует лишь малую часть динамического диапазона (например, из-за низкого уровня записи), эффективная битовая глубина снижается. Поэтому критически важно обеспечивать оптимальный уровень записи, при котором сигнал использует максимально возможную часть доступного диапазона без клиппинга.

Для уменьшения слышимости шума квантования при понижении битовой глубины (например, при конвертации из 24-бит в 16-бит для создания CD) применяется техника \emph{дитеринга} (dithering) — добавление специально подобранного низкоуровневого шума перед квантованием. Парадоксально, но добавление шума улучшает субъективное качество звука, превращая коррелированные искажения квантования в некоррелированный шум, который воспринимается слухом как менее навязчивый.

\subsection{Импульсно-кодовая модуляция (PCM) и контейнеры}
PCM (Pulse Code Modulation) является фундаментальным методом цифрового представления аналоговых сигналов, объединяющим процессы дискретизации, квантования и кодирования. В формате PCM каждый отсчет представляется в виде целого числа фиксированной разрядности.

Контейнеры WAV (Waveform Audio File Format) и AIFF (Audio Interchange File Format) служат для хранения PCM-потоков и метаданных. WAV, разработанный Microsoft и IBM, широко используется в Windows-средах, в то время как AIFF является стандартом для платформ Apple. Оба формата поддерживают различные частоты дискретизации, разрядности и число каналов.

Для практической передачи и хранения PCM-аудио обычно применяют сжатие — как без потерь (lossless), так и с потерями (lossy), что будет подробно рассмотрено в следующих разделах.

% ----------------- вопрос 2 -----------------
\section{Методы кодирования, декодирования и передачи аудиосигналов}
Раздел опирается на технические спецификации стандартов передачи \cite{pan1995,bosi2002,opus2024}.

\subsection{АЦП и ЦАП — цепочка кодирования и восстановления}
Процесс аналого-цифрового преобразования (АЦП) включает несколько критически важных этапов, каждый из которых вносит свой вклад в качество конечного результата:

\begin{enumerate}
    \item \textbf{Антиалиасинговый фильтр} — аналоговый ФНЧ (фильтр низких частот) с крутым срезом, подавляющий частоты выше $F_s/2$. Этот фильтр является первым и критически важным элементом тракта оцифровки. Его задача — гарантировать, что в оцифровываемом сигнале отсутствуют частотные компоненты выше частоты Найквиста. Конструкция этого фильтра представляет собой компромисс между крутизной среза (насколько резко фильтр подавляет частоты выше граничной), линейностью фазовой характеристики и стоимостью реализации. Современные sigma-delta АЦП используют oversampling (передискретизацию) для снижения требований к аналоговому антиалиасинговому фильтру.
    
    \item \textbf{Дискретизатор} — устройство взятия отсчетов, работающее с точно контролируемой частотой. Стабильность и точность тактовой частоты (clock) критически важны — даже незначительные флуктуации (jitter) могут привести к заметному ухудшению качества звука, особенно на высоких частотах. В профессиональном оборудовании используются высокоточные кварцевые генераторы или системы синхронизации от внешнего мастер-клока.
    
    \item \textbf{Квантователь} — преобразование непрерывных значений амплитуды в дискретные уровни. Современные АЦП используют различные архитектуры квантования: flash (параллельное сравнение со всеми уровнями одновременно, очень быстро, но дорого), successive approximation (последовательное приближение, хороший компромисс), sigma-delta (с шумоформированием и oversampling, очень высокое разрешение).
    
    \item \textbf{Кодер} — представление квантованных значений в двоичном коде, обычно в формате two's complement для знаковых целых чисел. На этом этапе также может применяться дитеринг и шумоформирование для оптимизации субъективного качества.
\end{enumerate}

На стороне воспроизведения цифро-аналоговый преобразователь (ЦАП) выполняет обратные операции:

\begin{enumerate}
    \item \textbf{Декодер} — преобразование двоичного кода обратно в дискретные уровни амплитуды. Точность декодирования и линейность преобразования критически важны для качества воспроизведения.
    
    \item \textbf{Экстраполятор} — формирование ступенчатого сигнала из последовательности отсчетов. Простейший вариант — удержание значения отсчета до следующего отсчета (zero-order hold). Более совершенные ЦАП используют интерполяцию и oversampling для формирования более гладкого сигнала.
    
    \item \textbf{Фильтр восстановления} (reconstruction filter или smoothing filter) — аналоговый фильтр низких частот, сглаживающий ступенчатый сигнал для восстановления непрерывной формы волны. Согласно теореме Котельникова-Найквиста, идеальный фильтр восстановления с частотой среза на частоте Найквиста полностью восстановит исходный сигнал. На практике используются фильтры с определенной полосой перехода, а применение oversampling в ЦАП позволяет использовать более простые аналоговые фильтры.
\end{enumerate}

Качество всего тракта преобразования определяется характеристиками каждого компонента, особенно точностью синхронизации и линейностью преобразователей. Современные профессиональные АЦП и ЦАП достигают уровня искажений ниже -120 дБ и динамического диапазона более 120 дБ, что превосходит возможности аналоговых систем и человеческого слуха.

\subsection{Каналы передачи и протоколы}
Для потоковой передачи аудио используются специализированные протоколы, адаптированные под различные сценарии применения:

\begin{itemize}
    \item \textbf{RTP/RTCP} (Real-time Transport Protocol / RTP Control Protocol) — стандартизированные протоколы для передачи мультимедийных данных в реальном времени через IP-сети. RTP работает поверх UDP и не гарантирует доставку пакетов, но обеспечивает механизмы для синхронизации потоков и обнаружения потерянных пакетов. RTCP предоставляет обратную связь о качестве передачи. Эти протоколы широко используются в VoIP-телефонии, видеоконференцсвязи и профессиональном аудио-стриминге.
    
    \item \textbf{HLS/DASH} (HTTP Live Streaming / Dynamic Adaptive Streaming over HTTP) — адаптивные протоколы для HTTP-стриминга. Они разбивают аудиопоток на короткие сегменты (обычно 2–10 секунд) и кодируют каждый сегмент в нескольких вариантах качества. Клиент динамически выбирает подходящий вариант в зависимости от доступной пропускной способности сети. Эти протоколы обеспечивают надежную доставку через стандартный HTTP, легко проходят через firewalls и используют существующую CDN-инфраструктуру.
    
    \item \textbf{WebRTC} (Web Real-Time Communication) — комплексная технология для браузерной коммуникации в реальном времени без необходимости установки плагинов. Включает кодеки (Opus для аудио), протоколы передачи, механизмы NAT traversal и адаптивное управление битрейтом. Широко применяется в веб-конференциях, онлайн-играх и других интерактивных приложениях.
    
    \item \textbf{Dante, AVB, AES67} — профессиональные протоколы для передачи многоканального аудио по Ethernet-сетям с гарантированной низкой задержкой и синхронизацией. Используются в студиях, концертных площадках и инсталляциях.
\end{itemize}

Ключевые требования к системам передачи различаются в зависимости от применения:

\begin{itemize}
    \item \textbf{Минимальная задержка} (latency) — критична для интерактивных применений (видеоконференции, онлайн-музыкальное сотрудничество, живые трансляции). Задержка более 150–200 мс начинает мешать естественному диалогу. Для музыкального взаимодействия требуется еще меньшая задержка — менее 30 мс.
    
    \item \textbf{Устойчивость к потерям пакетов} — в ненадежных сетях часть пакетов может теряться. Применяются техники packet loss concealment (PLC) — интерполяция потерянных фрагментов на основе соседних, использование избыточности (FEC — forward error correction) и адаптивные буферы для сглаживания джиттера.
    
    \item \textbf{Адаптивный битрейт} — способность динамически изменять качество кодирования в зависимости от доступной пропускной способности. Современные кодеки (Opus) могут плавно изменять битрейт в очень широком диапазоне (от 6 до 510 кбит/с) без разрыва потока.
\end{itemize}

% ----------------- вопрос 3 -----------------
\section{Сжатие аудиоданных: Lossless vs Lossy}
Материалы основаны на трудах по компрессии \cite{sayood2017,salomon2010}.

\subsection{Зачем нужно сжатие и классификация методов}
Цель сжатия аудиоданных — существенное сокращение объема данных при сохранении приемлемого или идентичного исходному качества. Несжатое стерео аудио CD-качества (44.1~кГц, 16 бит) требует битрейта 1411.2~кбит/с, что создает серьезные проблемы для хранения и передачи.

Рассмотрим конкретные цифры: одна минута несжатого CD-качества занимает примерно 10.6 МБ, час — около 635 МБ. Типичный музыкальный альбом длительностью 50 минут займет более 500 МБ. В эпоху модемного интернета 1990-х годов (с типичными скоростями 28.8–56 кбит/с) загрузка одной песни могла занимать часы. Даже при современных скоростях широкополосного интернета передача несжатого аудио создает значительную нагрузку на сети, особенно для потоковых сервисов, обслуживающих миллионы пользователей одновременно.

Методы сжатия делятся на две принципиально различные категории:

\begin{itemize}
    \item \textbf{Lossless (без потерь)} — гарантирует битовую идентичность восстановленных данных исходным. После декомпрессии получается точно такой же битовый поток, что и до компрессии. Эти методы используют статистические закономерности в данных и устранение избыточности, но не удаляют никакой информации. Типичный коэффициент сжатия для аудио составляет 1.5:1 — 3:1, то есть сжатие примерно в 2 раза.
    
    \item \textbf{Lossy (с потерями)} — жертвует частью информации для достижения значительно большего коэффициента сжатия. Эти методы основаны на психоакустических моделях человеческого слуха и удаляют компоненты сигнала, которые теоретически не должны восприниматься слушателем. Типичный коэффициент сжатия — от 5:1 до 20:1 и выше, в зависимости от требований к качеству.
\end{itemize}

Выбор между ними определяется требованиями конкретного применения:

\begin{itemize}
    \item \textbf{Lossless необходим для}: архивирования мастер-записей, профессиональной обработки и редактирования (где многократная перекомпрессия может накапливать артефакты), аудиофильских коллекций, научных и медицинских приложений, где важна абсолютная точность.
    
    \item \textbf{Lossy оптимален для}: потокового вещания (где важна низкая задержка и экономия трафика), мобильных устройств с ограниченной памятью, интернет-радио, подкастов, фоновой музыки, систем телефонии и видеоконференций.
\end{itemize}

\subsection{Lossless-компрессия: методы и форматы}
Форматы без потерь (FLAC, ALAC, APE, WavPack, TTA) используют различные комбинации алгоритмов сжатия, но общая схема обычно включает следующие этапы:

\begin{itemize}
    \item \textbf{Линейное предсказание} (Linear Prediction) — один из ключевых методов компрессии аудио. Идея заключается в том, что соседние отсчеты аудиосигнала обычно сильно коррелированы — текущий отсчет можно с хорошей точностью предсказать на основе нескольких предыдущих. Вместо кодирования самих отсчетов кодируются \emph{остатки предсказания} (prediction residuals) — разность между реальным значением и предсказанным. Эти остатки имеют значительно меньший динамический диапазон и могут быть закодированы более эффективно.
    
    Математически линейное предсказание выражается как:
    $$\hat{x}[n] = \sum_{k=1}^{p} a_k \cdot x[n-k]$$
    где $\hat{x}[n]$ — предсказанное значение, $a_k$ — коэффициенты предсказания, $p$ — порядок предсказателя. Остаток: $r[n] = x[n] - \hat{x}[n]$.
    
    \item \textbf{Кодирование Райса/Голомба} (Rice/Golomb coding) — специализированные методы энтропийного кодирования, оптимизированные для кодирования остатков предсказания, которые обычно имеют геометрическое или экспоненциальное распределение. Эти методы эффективнее универсального кодирования Хаффмана для такого типа данных.
    
    \item \textbf{Стерео декорреляция} (stereo decorrelation) — устранение избыточности между левым и правым каналами. Вместо независимого кодирования двух каналов кодируются средний (mid) и разностный (side) каналы:
    $$M = \frac{L + R}{2}, \quad S = L - R$$
    Для большинства музыкальных записей разностный канал имеет значительно меньшую амплитуду, что позволяет его эффективнее сжимать. При декодировании левый и правый каналы восстанавливаются как:
    $$L = M + \frac{S}{2}, \quad R = M - \frac{S}{2}$$
    
    \item \textbf{Адаптивная блочная обработка} — разделение аудиопотока на блоки и индивидуальная оптимизация параметров компрессии для каждого блока в зависимости от характеристик сигнала.
\end{itemize}

\textbf{FLAC} (Free Lossless Audio Codec) является наиболее распространенным форматом благодаря открытым спецификациям, свободной лицензии и широкой поддержке. Он обеспечивает сжатие обычно в диапазоне 2:1–3:1 в зависимости от сложности аудиоматериала \cite{flac2024}. Простые синусоидальные сигналы или тишина сжимаются очень эффективно, в то время как сложные плотные миксы или звуки с высокой энтропией (например, белый шум) почти не сжимаются.

FLAC поддерживает различные уровни компрессии (0–8), определяющие компромисс между степенью сжатия и скоростью кодирования. Более высокие уровни требуют больше вычислительных ресурсов при кодировании, но декодирование происходит с одинаковой скоростью независимо от уровня компрессии.

\subsection{Lossy-компрессия и психоакустические основы}
Алгоритмы сжатия с потерями основаны на \emph{психоакустических моделях} — математических описаниях особенностей человеческого слуха, позволяющих определить, какие компоненты сигнала могут быть удалены без заметного ухудшения субъективного качества:

\begin{itemize}
    \item \textbf{Абсолютный порог слышимости} (Absolute Threshold of Hearing, ATH) — минимальная интенсивность звука, которую способен различить человек на каждой частоте в условиях полной тишины. Этот порог имеет частотную зависимость: слух наиболее чувствителен в диапазоне 2–5 кГц и менее чувствителен на низких и высоких частотах. Любые компоненты сигнала ниже ATH могут быть безопасно удалены — они физически не воспринимаются слухом.
    
    \item \textbf{Частотная маскировка} (Simultaneous Masking) — явление, при котором мощный звук на определенной частоте подавляет восприятие более тихих звуков на близких частотах. Маскирующий эффект распространяется несимметрично: больше в сторону высоких частот. Это означает, что если в музыке присутствует громкий бас, более тихие высокочастотные компоненты в определенном диапазоне частот вокруг основной частоты баса не будут слышны и могут быть удалены или закодированы с меньшей точностью.
    
    \item \textbf{Временная маскировка} (Temporal Masking) — эффект маскировки, распространяющийся во времени. Включает пре-маскировку (pre-masking, до появления громкого звука, эффект длится 5–20 мс) и пост-маскировку (post-masking, после исчезновения громкого звука, может длиться 50–200 мс). Эти эффекты связаны с инерционностью слуховой системы и процессами обработки в мозге.
    
    \item \textbf{Критические полосы} (Critical Bands) — частотные диапазоны, в пределах которых звуки взаимодействуют в процессе слухового восприятия. Слуховая система человека разделяет входящий звук на примерно 24 критические полосы. Ширина критической полосы составляет примерно 100 Гц на низких частотах и увеличивается до 4 кГц на высоких частотах. Звуки в пределах одной критической полосы конкурируют за "слуховое внимание", и маскировка наиболее сильна именно внутри критических полос.
\end{itemize}

На основе этих моделей алгоритмы perceptual coding выполняют следующую последовательность операций:

\begin{enumerate}
    \item \textbf{Анализ сигнала} — преобразование временного сигнала в частотную область (обычно с помощью Modified Discrete Cosine Transform, MDCT), что позволяет анализировать и обрабатывать различные частотные компоненты независимо.
    
    \item \textbf{Построение психоакустической модели} — определение для каждой частотной компоненты порога маскировки, ниже которого компоненты не будут слышны.
    
    \item \textbf{Квантование} — кодирование частотных компонентов с разрешением, определяемым их слышимостью. Важные, хорошо слышимые компоненты кодируются с высокой точностью, маскируемые — с низкой или вообще отбрасываются.
    
    \item \textbf{Энтропийное кодирование} — дополнительное сжатие квантованных данных с использованием кодирования Хаффмана или арифметического кодирования.
    
    \item \textbf{Битовое распределение} — распределение доступных бит между различными частотными компонентами для максимизации субъективного качества при заданном битрейте.
\end{enumerate}

% ----------------- вопрос 4 -----------------
\section{Основные аудиоформаты и кодеки}
Обзор опирается на спецификации кодеков \cite{flac2024,opus2024}.

\subsection{MP3 — первый массовый формат}
MP3 (MPEG-1/2 Audio Layer III) стал революционным форматом, определившим развитие цифровой музыки в конце 1990-х — начале 2000-х годов. Разработанный исследовательским институтом Fraunhofer в Германии и стандартизированный в 1991 году, MP3 сделал возможным массовое распространение музыки через интернет и положил начало цифровой революции в музыкальной индустрии.

Архитектура MP3 включает несколько ключевых компонентов:

\begin{itemize}
    \item \textbf{Полифазный фильтр-банк} — разделяет входной сигнал на 32 частотных поддиапазона равной ширины. Это первичная частотная декомпозиция, обеспечивающая грубое частотное разрешение.
    
    \item \textbf{MDCT} (Modified Discrete Cosine Transform) — применяется к каждому из 32 поддиапазонов, дополнительно разбивая их на более узкие частотные бины. В итоге сигнал представляется 576 частотными коэффициентами для каждого канала. MDCT обладает важным свойством критической дискретизации и отсутствия избыточности во временной области.
    
    \item \textbf{Психоакустическая модель} — анализирует спектр сигнала и определяет, какие частотные компоненты маскируются другими и могут быть закодированы с меньшей точностью или удалены. MP3 использует две психоакустические модели различной сложности.
    
    \item \textbf{Квантование и кодирование} — частотные коэффициенты квантуются с разрешением, определяемым психоакустической моделью. Используется нелинейное квантование и энтропийное кодирование Хаффмана для эффективного представления квантованных значений.
    
    \item \textbf{Битовый резервуар} (bit reservoir) — механизм, позволяющий перераспределять биты между фреймами, выделяя больше бит сложным участкам и меньше — простым, что обеспечивает более стабильное качество при постоянном битрейте.
\end{itemize}

MP3 поддерживает различные битрейты от 32 до 320 кбит/с. Типичные применения:
\begin{itemize}
    \item 128 кбит/с — минимальный битрейт для приемлемого качества музыки, использовался в ранних интернет-радио
    \item 192 кбит/с — хорошее качество для большинства слушателей и условий воспроизведения
    \item 256–320 кбит/с — высокое качество, трудноотличимое от CD для большинства людей
\end{itemize}

Несмотря на появление более совершенных кодеков, MP3 остается широко распространенным благодаря универсальной поддержке и огромным архивам контента в этом формате.

\subsection{AAC — наследник MP3}
Advanced Audio Coding (AAC) был разработан как преемник MP3 и стандартизирован в 1997 году как часть MPEG-2, позднее расширен в MPEG-4. AAC обеспечивает заметно лучшее качество при тех же битрейтах благодаря ряду усовершенствований:

\begin{itemize}
    \item \textbf{Более эффективный фильтр-банк} — чистый MDCT без промежуточного полифазного фильтра, что обеспечивает лучшее частотное разрешение
    
    \item \textbf{Улучшенная психоакустическая модель} — более точное моделирование маскирующих эффектов
    
    \item \textbf{Временное формирование шума} (Temporal Noise Shaping, TNS) — контроль временной структуры артефактов квантования
    
    \item \textbf{Предсказание} — использование корреляции между последовательными фреймами
    
    \item \textbf{Coupling} — эффективное кодирование стереосигнала
\end{itemize}

AAC существует в нескольких профилях:
\begin{itemize}
    \item \textbf{AAC-LC} (Low Complexity) — базовый профиль, используемый в iTunes, YouTube, большинстве потоковых сервисов
    \item \textbf{HE-AAC} (High Efficiency) — оптимизирован для низких битрейтов (32–64 кбит/с) с использованием технологии Spectral Band Replication (SBR)
    \item \textbf{HE-AAC v2} — добавляет Parametric Stereo для еще более эффективного кодирования стерео на низких битрейтах
\end{itemize}

AAC стал де-факто стандартом для потокового вещания и мобильных устройств, вытеснив MP3 в новых применениях.

\subsection{Opus — современный универсальный кодек}
Opus, стандартизированный IETF в 2012 году (RFC 6716), представляет собой наиболее современный аудиокодек общего назначения, сочетающий преимущества двух различных технологий \cite{opus2024}:

\begin{itemize}
    \item \textbf{SILK} — кодер на основе линейного предсказания (LPC), оптимизированный для кодирования речи. Эффективен на низких битрейтах (6–20 кбит/с) и обеспечивает отличную разборчивость речи.
    
    \item \textbf{CELT} — кодер на основе MDCT, оптимизированный для музыки. Обеспечивает высокое качество музыки при средних и высоких битрейтах.
\end{itemize}

Opus автоматически выбирает режим или комбинацию режимов в зависимости от типа контента, обеспечивая отличное качество в исключительно широком диапазоне битрейтов от 6 до 510 кбит/с. Ключевые преимущества:

\begin{itemize}
    \item \textbf{Универсальность} — одинаково хорошо работает с речью и музыкой
    \item \textbf{Низкая задержка} — алгоритмическая задержка всего 5–66.5 мс в зависимости от режима, что критично для интерактивных применений
    \item \textbf{Адаптивность} — плавное изменение битрейта без разрывов
    \item \textbf{Устойчивость к потерям пакетов} — встроенные механизмы маскирования потерь
    \item \textbf{Открытость} — свободная лицензия без роялти
\end{itemize}

Opus быстро становится стандартом для WebRTC, VoIP, потокового вещания и других применений, требующих высокого качества при ограниченной пропускной способности.

\subsection{FLAC и другие lossless-форматы}
FLAC (Free Lossless Audio Codec) остается доминирующим стандартом для сжатия без потерь благодаря открытым спецификациям, широкой поддержке и эффективности \cite{flac2024}:

\begin{itemize}
    \item \textbf{Открытость} — полностью открытые спецификации, свободная реализация
    \item \textbf{Поддержка} — воспроизводится практически всеми современными плеерами и DAW
    \item \textbf{Метаданные} — богатая система тегов на основе Vorbis Comments
    \item \textbf{Streaming} — поддержка потоковой обработки с минимальной задержкой
    \item \textbf{Верификация} — встроенные MD5-checksums для проверки целостности
\end{itemize}

Альтернативные lossless-форматы:
\begin{itemize}
    \item \textbf{ALAC} (Apple Lossless) — проприетарный формат Apple, позднее открытый. Похожие характеристики на FLAC, но несколько менее эффективный
    \item \textbf{WavPack} — гибридный формат, поддерживающий как lossless, так и lossy режимы
    \item \textbf{APE} (Monkey's Audio) — обеспечивает несколько лучшее сжатие, но медленнее и менее широко поддерживается
    \item \textbf{TAK} — отличное сжатие и скорость, но проприетарный и ограниченная поддержка
\end{itemize}

Для большинства применений FLAC представляет оптимальный выбор благодаря балансу эффективности, скорости и универсальной поддержки.

% ----------------- вопрос 5 -----------------
\section{Редактирование и обработка аудио}
Раздел описывает практические аспекты работы с аудио в цифровых рабочих станциях.

\subsection{Digital Audio Workstations (DAW)}
Современные цифровые аудиорабочие станции (DAW) представляют собой комплексные программные среды, объединяющие полный набор инструментов для всех этапов работы с аудио — от записи до финального мастеринга. DAW превратили персональные компьютеры в мощные студии звукозаписи, демократизировав доступ к профессиональным инструментам производства музыки.

Основные категории DAW и их специализация:

\begin{itemize}
    \item \textbf{Pro Tools} — индустриальный стандарт для пост-продакшна кино и телевидения, профессиональной музыкальной записи. Отличается исключительной стабильностью, продвинутыми возможностями редактирования и широчайшей поддержкой профессионального оборудования. Традиционно требовательный к аппаратуре (фирменные аудиоинтерфейсы), но современные версии работают с любым оборудованием.
    
    \item \textbf{Logic Pro} — флагманская DAW от Apple для платформы macOS. Особенно популярна среди композиторов электронной музыки и хип-хопа благодаря богатой библиотеке виртуальных инструментов, лупов и превосходной MIDI-функциональности. Интеграция с экосистемой Apple обеспечивает seamless workflow.
    
    \item \textbf{Ableton Live} — уникальная DAW с двухрежимной архитектурой: Session View для нелинейной импровизации и живых выступлений, и Arrangement View для традиционного линейного редактирования. Стала стандартом для электронной музыки, live performance и экспериментального звука. Мощные возможности для работы с лупами, real-time эффектами и автоматизацией.
    
    \item \textbf{Reaper} — легковесная, быстрая и исключительно гибкая DAW с невысокой ценой. Отличается глубокими возможностями кастомизации, эффективным использованием системных ресурсов и активным сообществом разработчиков скриптов и расширений. Популярна среди подкастеров, звукорежиссеров игр и тех, кто ценит производительность.
    
    \item \textbf{Cubase} — одна из старейших DAW, традиционно сильная в MIDI-секвенсировании и работе с виртуальными инструментами. Широко используется композиторами для кино, игр и симфонической музыки.
    
    \item \textbf{FL Studio} — бывшая FruityLoops, изначально ориентированная на создание битов и электронной музыки. Отличается уникальным workflow с pattern-based секвенсором и исключительно intuitive интерфейсом для начинающих.
    
    \item \textbf{Audacity} — бесплатный open-source аудиоредактор, не полноценная DAW, но превосходный инструмент для базового редактирования, записи, конвертации форматов и простой обработки. Идеален для подкастинга, оцифровки записей и quick editing tasks.
\end{itemize}

Все современные DAW предоставляют базовый набор функций: многодорожечная запись и воспроизведение, неразрушающее редактирование, автоматизация параметров, поддержка VST/AU плагинов, MIDI-секвенсирование, микширование и экспорт в различные форматы.

\subsection{Основные операции редактирования}
Фундаментальные операции редактирования аудио составляют основу любой работы в DAW:

\begin{itemize}
    \item \textbf{Cut/Copy/Paste} — базовые операции с фрагментами аудио, аналогичные текстовому редактированию. Позволяют перемещать, дублировать и удалять секции. В профессиональной работе критически важна точность позиционирования (обычно с привязкой к сетке или транзиентам) и обработка граничных точек для избежания щелчков.
    
    \item \textbf{Fade in/out и кроссфейды} — сглаживание начала и конца клипов для предотвращения артефактов при склейке. Различные формы фейдов (линейный, экспоненциальный, S-образный) используются в зависимости от материала. Кроссфейды обеспечивают плавный переход между соседними клипами без разрывов.
    
    \item \textbf{Нормализация} — выравнивание уровня громкости путем пропорционального масштабирования всех отсчетов. Peak normalization поднимает уровень до тех пор, пока максимальный пик не достигнет заданного значения (обычно -0.3 или -1 дБFS). RMS normalization выравнивает воспринимаемую громкость. Loudness normalization (по стандартам EBU R128, ITU-R BS.1770) обеспечивает единообразную громкость для вещания и стриминга.
    
    \item \textbf{Time-stretching} — изменение длительности аудио без изменения высоты тона. Использует сложные алгоритмы (phase vocoder, granular synthesis, формантное сохранение) для поддержания естественности звучания. Современные алгоритмы (Élastique, Radius) обеспечивают высокое качество даже при значительных изменениях темпа (0.5x–2x).
    
    \item \textbf{Pitch-shifting} — изменение высоты тона без изменения длительности. Используется для коррекции исполнения, транспонирования, создания гармоний и специальных эффектов. Качество критически зависит от алгоритма — простые методы создают заметные артефакты (metallic звучание), продвинутые (формантное сохранение, spectral modeling) звучат естественно.
    
    \item \textbf{Reverse} — воспроизведение в обратном направлении, часто используется для создания уникальных реверберационных эффектов и психоделического звучания.
    
    \item \textbf{Strip silence} — автоматическое удаление или заглушение участков с уровнем ниже заданного порога. Полезно для очистки записей от фонового шума в паузах, уплотнения сессий и подготовки материала для слайсинга.
\end{itemize}

\subsection{Обработка эффектами и плагины}
Современная обработка аудио реализуется через плагины — программные модули, выполняющие специфические виды обработки. Основные категории:

\begin{itemize}
    \item \textbf{Эквализация (EQ)} — избирательное усиление или ослабление определенных частотных диапазонов. Параметрический EQ позволяет контролировать частоту, добротность (Q) и усиление каждой полосы. Используется для коррекции тембра, устранения резонансов, разделения частотного пространства в миксе. Графический EQ предоставляет фиксированные полосы для быстрой общей коррекции. Динамический EQ сочетает эквализацию с компрессией, реагируя только на определенные уровни сигнала.
    
    \item \textbf{Динамическая обработка} — контроль уровня и динамического диапазона:
    \begin{itemize}
        \item \emph{Компрессоры} — уменьшают динамический диапазон, подавляя громкие звуки относительно тихих. Параметры: threshold (порог срабатывания), ratio (степень компрессии), attack (время реакции), release (время восстановления), makeup gain (компенсация уровня)
        \item \emph{Лимитеры} — экстремальная компрессия (infinite ratio) для предотвращения клиппинга
        \item \emph{Экспандеры и гейты} — обратные компрессору процессы, расширяющие динамику или подавляющие тихие звуки
        \item \emph{Многополосная компрессия} — независимая компрессия разных частотных диапазонов для точного контроля
    \end{itemize}
    
    \item \textbf{Реверберация} — имитация акустики помещений различного размера и характера. Алгоритмические реверберации (Lexicon, EMT algorithms) создают синтетические пространства. Convolution reverb использует импульсные характеристики реальных помещений для фотореалистичного звучания.
    
    \item \textbf{Задержка (Delay)} — повторения сигнала через определенные интервалы времени. От короткой задержки (slapback echo, 40–120 мс) до длинных ритмических повторов. Ping-pong delay, tape delay эмуляции, фильтрованные задержки создают разнообразные эффекты.
    
    \item \textbf{Модуляционные эффекты} — chorus (утолщение звука), flanger (гребенчатая фильтрация со движущимися резонансами), phaser (фазовые сдвиги), tremolo (амплитудная модуляция), vibrato (частотная модуляция).
    
    \item \textbf{Saturation и Distortion} — добавление гармонических искажений для теплоты, характера, агрессии. От subtle tape saturation до экстремального гитарного distortion.
    
    \item \textbf{Пространственная обработка} — stereo widening, panning, binaural processing, управление стереобазой и глубиной.
\end{itemize}

Профессиональный workflow обычно включает последовательность: коррекция проблем (EQ, de-noise), затем динамическая обработка, затем креативные эффекты и финальная полировка.

% ----------------- вопрос 6 -----------------
\section{Пространственное и объемное аудио}
Обзор современных технологий иммерсивного звука.

\subsection{Эволюция пространственного звука}
История пространственного звука начинается с изобретения стереофонии в 1930-х годах, когда Alan Blumlein разработал концепцию двухканальной записи для создания иллюзии пространства. С тех пор технология прошла долгий путь от простого стерео к многоканальным системам объемного звучания и современным объектным форматам.

Традиционная эволюция включала: моно, стерео, квадрафонию (неудачный эксперимент 1970-х), объемный звук 5.1 (Dolby Digital, 1992), 7.1 и расширенные конфигурации, современные иммерсивные форматы с высотными каналами. Каждый этап добавлял новые измерения к звуковому полю и улучшал способность создавать убедительную пространственную картину.

\subsection{Форматы пространственного звука}
Современные технологии пространственного аудио можно разделить на несколько категорий в зависимости от подхода к кодированию и воспроизведению:

\begin{itemize}
    \item \textbf{Dolby Atmos} — наиболее широко распространенный формат объектного аудио, представленный в 2012 году. В отличие от традиционных channel-based форматов, Atmos описывает звук как совокупность объектов, каждый из которых имеет метаданные о своем положении в трехмерном пространстве. Система воспроизведения (renderer) динамически адаптирует микс к конкретной конфигурации динамиков, от 5.1.2 (5 основных + сабвуфер + 2 высотных) до массивных кинотеатральных систем 24.1.10 или даже больше.
    
    Ключевые преимущества Atmos:
    \begin{itemize}
        \item Масштабируемость — один микс адаптируется к любой конфигурации от саундбара до полноценного кинотеатра
        \item Точное позиционирование звука в трехмерном пространстве включая высоту
        \item Более эффективное использование каналов — звуки направляются только туда, где они должны быть слышны
        \item Поддержка до 128 одновременных объектов плюс 10 базовых каналов (bed)
        \item Binaural рендеринг для наушников, создающий 3D-эффект без физических динамиков
    \end{itemize}
    
    Atmos используется в кинотеатрах, домашних системах, стриминговых сервисах (Apple Music, Tidal, Amazon Music), играх и виртуальной реальности.
    
    \item \textbf{DTS:X} — конкурирующий формат объектного аудио от DTS, представленный в 2015 году. Философия схожа с Atmos: object-based подход, адаптивный рендеринг, поддержка высотных каналов. Отличия включают большую гибкость в конфигурации динамиков (не требует специфических позиций) и отсутствие жестких ограничений на количество объектов.
    
    DTS:X позволяет индивидуально регулировать громкость диалога отдельно от остального микса — полезная accessibility функция. Формат менее распространен чем Atmos, но поддерживается многими AV-ресиверами и используется в части кинофильмов.
    
    \item \textbf{Ambisonics} — фундаментально иной подход к пространственному аудио, основанный на математическом описании звукового поля как совокупности сферических гармоник. Вместо дискретных каналов или объектов, Ambisonics кодирует всю информацию о звуковом поле в наборе коэффициентов.
    
    Основные свойства Ambisonics:
    \begin{itemize}
        \item \emph{Scene-based} подход — кодируется всё звуковое окружение целиком
        \item Полная независимость от конфигурации воспроизведения — декодирование возможно для любой расстановки динамиков
        \item Поддержка вращения звукового поля без потери качества — идеально для VR/AR где ориентация пользователя постоянно меняется
        \item Масштабируемость через порядки (order) — первый порядок (4 канала B-format) даёт базовое направление, высшие порядки (до 7-го и выше в исследованиях, 16+ каналов) обеспечивают более точную локализацию
        \item Относительная простота записи с помощью специализированных микрофонов (тетраэдрические массивы, сферические микрофонные массивы)
    \end{itemize}
    
    Ambisonics особенно популярен в академической среде, 360-градусном видео, виртуальной реальности и инсталляционном искусстве. Форматы файлов включают AmbiX (стандартизированный ACN/SN3D формат) и FuMa (устаревший B-format).
    
    \item \textbf{Binaural audio} — техника создания трехмерного звука специально для воспроизведения в наушниках. Основана на HRTF (Head-Related Transfer Function) — математических моделях того, как человеческая голова, ушные раковины и торс фильтруют звук в зависимости от направления его прихода.
    
    Бинауральная обработка учитывает:
    \begin{itemize}
        \item ITD (Interaural Time Difference) — разница во времени прихода звука к двум ушам, основной cue для локализации по горизонтали
        \item ILD (Interaural Level Difference) — разница в уровне, вызванная затенением головой, важна на высоких частотах
        \item Спектральные изменения, создаваемые формой ушных раковин, критичны для определения высоты источника
        \item Эффект реверберации и отражений от торса
    \end{itemize}
    
    Качественный бинауральный рендеринг требует индивидуализированных HRTF (каждый человек имеет уникальную геометрию головы и ушей), но на практике обычно используются усредненные модели или модели, подбираемые из базы данных. Head tracking значительно улучшает иммерсивность, привязывая звуковое поле к пространству, а не к голове слушателя.
    
    \item \textbf{Sony 360 Reality Audio} — потребительский формат от Sony для музыкального стриминга, использующий object-based подход и MPEG-H 3D Audio кодек. Ориентирован на персонализированный бинауральный рендеринг с возможностью анализа формы ушей пользователя через мобильное приложение.
    
    \item \textbf{MPEG-H 3D Audio} — международный стандарт для next-generation вещания, поддерживающий channel-based, object-based и scene-based (HOA — Higher Order Ambisonics) аудио в едином битстриме. Включает интерактивные возможности (выбор языка, индивидуальные миксы) и эффективное кодирование.
\end{itemize}

\subsection{Применение в VR/AR и интерактивных медиа}
Пространственный звук критически важен для создания убедительного sense of presence в виртуальной и дополненной реальности. В то время как визуальная составляющая VR получает большую часть внимания, звук играет не менее важную роль в создании иммерсивности и часто является определяющим фактором в believability виртуального окружения.

\textbf{Технологии для VR/AR аудио:}

\begin{itemize}
    \item \textbf{Real-time 3D audio rendering} — динамическое позиционирование источников звука в трехмерном пространстве с учетом положения и ориентации головы пользователя. Требует минимальной задержки (latency) — задержка более 20 мс между движением головы и соответствующим изменением звука разрушает иллюзию.
    
    \item \textbf{Head tracking} — интеграция с системами отслеживания положения головы (6DoF — 6 degrees of freedom: 3 позиции + 3 вращения). Звуковое поле остается привязанным к виртуальному миру, а не следует за поворотами головы, что радикально улучшает локализацию и естественность.
    
    \item \textbf{HRTF персонализация} — адаптация передаточных функций к индивидуальным анатомическим особенностям пользователя. Методы включают измерение (требует специального оборудования), выбор из базы данных на основе антропометрических параметров, фотограмметрию ушей, машинное обучение для предсказания HRTF.
    
    \item \textbf{Акустическое моделирование окружения} — симуляция акустических свойств виртуального пространства: геометрии, материалов поверхностей, реверберации, окклюзии (блокирование звука объектами), обструкции (частичное блокирование). Технологии ray tracing и wave-based simulation позволяют создавать реалистичную акустику виртуальных помещений в реальном времени.
    
    \item \textbf{Пространственная реверберация} — реверберация должна меняться в зависимости от положения источника и слушателя в виртуальном пространстве. Ранние отражения особенно важны для sense of space и должны корректно моделироваться относительно геометрии.
\end{itemize}

\textbf{Платформы и middleware:}

\begin{itemize}
    \item \textbf{Steam Audio (Valve)} — open-source audio SDK для игр и VR с физически корректной акустикой
    \item \textbf{Resonance Audio (Google)} — мультиплатформенный SDK для spatial audio в мобильных, desktop и VR приложениях
    \item \textbf{Microsoft Spatial Sound} — Windows Sonic и Dolby Atmos for Headphones для платформы Windows и Xbox
    \item \textbf{Wwise и FMOD} — профессиональное audio middleware для игр с extensive поддержкой пространственного аудио
\end{itemize}

Правильно реализованный пространственный звук не только улучшает иммерсивность, но и служит важным gameplay элементом (локализация противников в shooter-играх), accessibility инструментом (звуковая навигация для слабовидящих в VR) и повышает comfort, снижая motion sickness через улучшенное соответствие аудио-визуальных cues.

% ----------------- заключение -----------------
\section{Заключение}
В данном реферате были рассмотрены ключевые аспекты современных технологий создания и обработки аудио: от фундаментальных принципов оцифровки до перспективных направлений развития пространственного звука. Понимание этих технологий необходимо для профессиональной работы с аудиоконтентом в различных областях медиаиндустрии.

Дальнейшее развитие аудиотехнологий будет связано с совершенствованием алгоритмов компрессии (в том числе с применением машинного обучения), расширением применения иммерсивных форматов и интеграцией аудио с другими модальностями в контексте XR-технологий.

% ----------------- список литературы -----------------
\printbibliography

\end{document}
