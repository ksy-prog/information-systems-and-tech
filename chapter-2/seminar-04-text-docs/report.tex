% реферат на тему "Технологии создания и обработки текстовых документов"

\documentclass{SibFU-docs}

% дополнительные пакеты для оформления
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{float}

\addbibresource{report.bib}

\begin{document}

% титульный лист
\makecovertitle{Гуманитарный институт}{Прикладная информатика в искусстве и интерактивных медиа}{Технологии создания и обработки текстовых документов}{ГФ25-02Б}

% аннотация
\section*{Аннотация}
\addcontentsline{toc}{section}{Аннотация}
В данной работе рассматриваются современные технологии представления, хранения и обработки текстовой информации. Раскрываются вопросы кодирования символов, форматов документов, языков разметки, семантики и метаданных, методов автоматической обработки текста и стратегий долговременного хранения. Работа опирается на набор учебных и нормативных источников, указанных в списке литературы.

% содержание
\tableofcontents
\newpage

% введение
\section{Введение}
Введение содержит обзор целей и структуры работы. В процессе подготовки использованы исходные конспекты подтем и сопутствующие стандартные документы: стандарт Unicode и материалы W3C для вопросов кодирования и нормализации \cite{unicode2024,rfc3629,w3c2024}, исследования и спецификации по форматам и открытым/проприетарным стандартам \cite{odf2024,ecma376,msft2024,iso32000}, источники по языкам разметки и системе LaTeX \cite{knuth1984texbook,latex_project,markdown_spec}, труды по метаданным и семантике \cite{dublincore,gilliland2016metadata}, современные обзоры методов автоматической обработки текста и тематического моделирования \cite{JMLR2003LDA,arXiv2011NER,Techtarget2024Sentiment}, а также рекомендации по долговременному хранению и PDF/A \cite{LOC2024PDFA,PDFAssociation2025ISO19005,Lucidea2024LongTermAccess}.

Цель работы: систематизировать знания по технологиям создания и обработки текстовых документов, предложить практические рекомендации по выбору форматов и методов обработки, а также рассмотреть основные подходы к долговременному хранению цифровых текстов.

Методика: работа представляет собой обзорную и аналитическую работу, где исходные конспекты дополнены примерами, таблицами и практическими рекомендациями. Каждый раздел содержит ссылки на использованные источники и краткие выводы, пригодные для практического применения.

\section{Представление и кодирование текстовых данных}

\subsection{Фундаментальные принципы}
Текстовые данные в вычислительных системах представляются в виде кодовых точек и последовательностей байтов. Кодирование — процесс сопоставления символов их числовым кодам и передачи в двоичной форме. Исторически первым стандартом был ASCII, затем появились различные 8-битные кодировки, а современным универсальным решением стал Unicode, реализуемый через UTF-8, UTF-16 и UTF-32 \cite{unicode2024,rfc3629,iso10646}.

\subsection{Практические аспекты и нормализация}
Обсуждены проблемы определения кодировки, использование BOM и важность нормализации Unicode для корректного сравнения строк и поиска \cite{w3c2024,iana2024}.

\subsection{Краткая историческая справка: ASCII и 8-битные кодировки}
ASCII стал первым повсеместно принятым стандартом кодирования текста и использовал 7 бит для представления базового набора символов (128 значений). По мере распространения компьютерных систем появились расширения до 8 бит (Windows-1251, ISO-8859-1 и др.), что породило проблему несовместимости между кодировками. Переход на Unicode (и UTF-8 как формат передачи) решил эти проблемы, объединив представление символов всех письменностей в единую систему \cite{petzold2001,tanenbaum2015}.

\subsection{Пример: представление строки в байтах}
Рассмотрим строку "Aё". В ASCII символ "A" кодируется как 0x41. В UTF-8 последовательность будет выглядеть так (в шестнадцатеричном виде):
\begin{verbatim}
A -> 41
ё -> D1 91  % UTF-8 encoding for U+0451
\end{verbatim}
Это демонстрирует, что различные символы занимают разное число байтов в UTF-8, и почему важно правильно обрабатывать кодировки при чтении и записи файлов.

\subsection{Детальное рассмотрение схем UTF}
UTF-8 — наиболее распространённый формат кодирования Unicode в файлах и в сети. Его преимущество в совместимости с ASCII и эффективности для латиницы. Ниже приведён сводный обзор соответствия диапазонов Unicode и длины кодирования в UTF-8.

\begin{table}[H]
\centering
\begin{tabular}{l l}
Диапазон Unicode & Длина в UTF-8 \\
\hline
U+0000 — U+007F & 1 байт \\
U+0080 — U+07FF & 2 байта \\
U+0800 — U+FFFF & 3 байта \\
U+10000 — U+10FFFF & 4 байта \\
\end{tabular}
\caption{Диапазоны Unicode и соответствующая длина в UTF-8}
\end{table}

\subsection{Практические советы по работе с кодировками}
При разработке ПО и подготовке документов рекомендуется:
\begin{itemize}
	\item Всегда сохранять текст в UTF-8 без BOM для совместимости с Unix-подобными системами.
	\item Явно указывать кодировку в HTTP-заголовке `Content-Type` и в мета-тегах HTML.
	\item При обмене данными использовать проверенные библиотеки для конвертации и нормализации Unicode.
	\item Применять NFC или NFKC нормализацию в задачах сравнения строк и поиска.
\end{itemize}

\subsection{Нормализация Unicode: формы и применение}
Unicode определяет несколько форм нормализации, наиболее распространённые из которых — NFC (Normalization Form C) и NFD (Normalization Form D), а также их совместимые версии NFKC и NFKD. NFC выполняет каноническую композицию символов (например, комбинированный акцент будет скомбинирован в один кодовый знак), а NFD — разложение на базовый символ и комбинирующие диакритические знаки. NFKC/NFKD выполняют совместимую нормализацию, которая может изменять визуальное представление для достижения совместимости (например, преобразование множества форм в единый канонический эквивалент).

Практическое применение:
\begin{itemize}
  \item Для целей сравнения и дедупликации данных рекомендуется использовать NFC.
  \item Для задач, где важно сохранять визуальную верность (например, в издательстве), нужно документировать, какая форма нормализации использована.
  \item При интеграции данных из разных источников рекомендуется фиксировать исходную кодировку и форму нормализации в метаданных.
\end{itemize}

\subsection{Endianness и BOM}
Проблемы порядка байтов (endianness) актуальны для UTF-16 и UTF-32. BOM (Byte Order Mark) может использоваться для указания порядка байтов, однако не рекомендуется на POSIX-системах для UTF-8, так как BOM в начале файла может интерпретироваться как невидимый символ. При разработке кроссплатформенных приложений следует предусматривать явную проверку и корректную обработку BOM.

\section{Форматы текстовых файлов: проприетарные и открытые}

\subsection{Классификация форматов}
Форматы разделяются на простые текстовые и форматированные документы. Проприетарные форматы предоставляют богатый функционал, но создают риски зависимости от вендора; открытые форматы гарантируют долговременную доступность и гибкость при конвертации \cite{odf2024,ecma376,msft2024}.

\subsection{Преимущества и недостатки: конкретные примеры}
Рассмотрим некоторые популярные форматы и их типичные сценарии использования.
\begin{itemize}
	\item \textbf{Plain Text (.txt, .csv)}: простота, переносимость, идеально для данных и логов. Ограничение — отсутствие форматирования.
	\item \textbf{PDF/PDF-A}: фиксированный макет, хорош для публикации и архивации. PDF/A обеспечивает самодостаточность за счёт встраивания шрифтов \cite{iso32000,PDFAssociation2025ISO19005}.
	\item \textbf{DOCX/OOXML}: мощные возможности редактирования и сложной семантики, но потенциальные риски при долговременном хранении из-за зависимости от спецификации \cite{ecma376,msft2024}.
	\item \textbf{ODF (.odt)}: открытый формат для офисных документов, хорошая альтернатива проприетарным форматам \cite{odf2024,iso26300}.
\end{itemize}

\subsection{Рекомендации по выбору формата}
Для архивирования и долговременного хранения рекомендуется использовать открытые стандарты: PDF/A, XML, ODF и пр. Для совместной работы в гетерогенных средах — ODF или общедоступные PDF \cite{iso26300,iso32000,LOC2024PDFA}.

\subsection{Метаинформация и встроенные метаданные}
Многие форматы поддерживают встроенные метаданные: PDF — XMP, DOCX — свойства пакета Open XML, ODF — собственные метаданные в meta.xml. При архивации важно извлекать и сохранять эти метаданные в единой базе описаний архива.

\subsection{Практический пример конвертации}
При переносе большого числа файлов из проприетарных форматов в архивные рекомендуется автоматизировать процесс и контролировать качество конверсии. Примерный pipeline:
\begin{enumerate}
	\item Инвентаризация исходных файлов (типы, размеры, метаданные).
	\item Групповая конвертация (например, DOCX → PDF/A) с помощью инструментов (LibreOffice, Ghostscript, специализированные конвертеры).
	\item Верификация (визуальная и автоматическая) и фиксация контрольных сумм.
	\item Создание AIP (Archival Information Package) с полными метаданными.
\end{enumerate}

\subsection{Пример команды для конвертации с использованием LibreOffice (CLI)}
Ниже пример использования LibreOffice в безголовом режиме для пакетной конвертации DOCX в PDF:
\begin{verbatim}
soffice --headless --convert-to pdf:writer_pdf_Export --outdir C:\path\to\out C:\path\to\file.docx
\end{verbatim}
Для получения PDF/A может потребоваться дополнительная обработка или использование специального фильтра при конвертации; также рекомендуется проверять результат специальными валидаторами PDF/A.

\section{Языки разметки и структурирование документов}

Языки разметки (HTML, Markdown, XML, LaTeX) позволяют отделять содержание от представления и обеспечивают переносимость и долговременную читаемость документов. LaTeX особенно важен для научной публикации и сложной типографики \cite{latex_project,markdown_spec,xml_w3c,bernerslee1992html}.

\subsection{Сравнение популярных языков разметки}
Ниже приведено краткое сравнение наиболее используемых языков разметки и их сильных сторон.
\begin{table}[H]
\centering
\begin{tabular}{p{3.5cm} p{10cm}}
Язык & Область применения и преимущества \\
\hline
HTML & Основной язык для представления веб-страниц; богатая семантика и поддержка мультимедиа \cite{w3c_html} \\
Markdown & Прост в использовании, идеален для документации и быстрого написания текстов; легко конвертируется в HTML или PDF \cite{markdown_spec} \\
XML & Подходит для структурированных данных и обмена информацией между системами; расширяемость схем \cite{xml_w3c} \\
LaTeX & Профессиональная типографика, мощные средства для формул и библиографии; стандарт в науке \cite{knuth1984texbook,latex_project} \\
\end{tabular}
\caption{Сравнение языков разметки}
\end{table}

\subsection{Пример XML-метаданных}
Ниже — минимальный пример блока метаданных в формате XML с использованием элементов Dublin Core:
\begin{verbatim}
<metadata>
	<dc:title>Пример документа</dc:title>
	<dc:creator>И. И. Иванов</dc:creator>
	<dc:date>2025-11-13</dc:date>
	<dc:language>ru</dc:language>
</metadata>
\end{verbatim}

\section{Семантическая организация и метаданные}

Семантическая разметка даёт возможность машинам понимать структуру документа; метаданные (Dublin Core и др.) обеспечивают поиск, идентификацию и долговременную доступность объектов \cite{dublincore,gilliland2016metadata,w3c_html}.

\subsection{Практическая интеграция метаданных в архиве}
Метаданные должны храниться в единой системе, где каждому объекту соответствует уникальный идентификатор и связанный набор полей Dublin Core/Qualified Dublin Core. Это облегчает поиск, предоставление прав доступа и анализ коллекции.

\section{Технологии автоматической обработки текстовой информации}

Обзор методов: от правил и статистики до нейросетей и трансформеров. Рассмотрены задачи предварительной обработки (токенизация, стемминг, лемматизация), NER, синтаксический и семантический анализ, тематическое моделирование (LDA), анализ тональности и методы суммаризации текста \cite{Educative2023Tokenization,JMLR2003LDA,arXiv2011NER,arXiv2023AbstractiveSummarization,Techtarget2024Sentiment}.

\subsection{Предварительная обработка данных}
Предобработка — ключевой этап. Типичный pipeline включает: нормализацию кодировки, приведение регистра, токенизацию, удаление стоп-слов, лемматизацию/стемминг и векторизацию (Bag-of-Words, TF-IDF, word2vec/embeddings).

\subsection{Методы тематического моделирования}
Методы как LDA позволяют выявлять скрытые темы в больших коллекциях текстов. Применение: анализ научных публикаций, кластеризация новостей, исследование трендов в социальных сетях \cite{JMLR2003LDA,Wikipedia2006LDA}.

\subsection{Современные нейросетевые подходы}
Трансформеры (BERT, GPT-подобные модели) обеспечили качественный скачок: они дают представления (embeddings), которые используются и для классификации, и для суммаризации, и для семантического поиска. Практические рекомендации:
\begin{itemize}
	\item Для задач с ограниченными данными — использовать предобученные модели и fine-tuning.
	\item Для больших корпусов — комбинировать extractive и abstractive подходы к суммаризации \cite{arXiv2023AbstractiveSummarization,MicrosoftLearn2025Summarization}.
\end{itemize}

\subsection{Пример: pipeline для NER}
Типичный конвейер для распознавания именованных сущностей включает: токенизацию, POS-теггинг, применение модели (CRF или BiLSTM/Transformer) и постобработку (включая привязку к внешним базам данных).

\subsection{Качество и валидация моделей}
Оценка качества моделей включает метрики точности (Precision, Recall, F1-score), а также процедуры валидации на отложенных наборах (cross-validation). Для тематического моделирования используется перплексия и coherence-score.

\subsection{Пример команд для проверки целостности (Windows PowerShell)}
Для вычисления SHA-256 контрольной суммы в PowerShell используйте:
\begin{verbatim}
Get-FileHash -Algorithm SHA256 C:\path\to\file.pdf
\end{verbatim}
Рекомендуется сохранять полученные хеши в реестре метаданных архива и выполнять периодические сверки.

\section{Долговременное хранение и архивация}

Стратегии: обновление носителя, миграция форматов, эмуляция. Рекомендуемые форматы: PDF/A, XML; значение контроля целостности (хеши SHA-256) и метаданных (Dublin Core) \cite{Lucidea2024LongTermAccess,PDFAssociation2025ISO19005,OrbisFileFixity2014,LOC2024PDFA}.

\section{Развёрнутое обсуждение подтем}
В этом разделе последовательно рассматриваются все шесть подтем с более глубокой проработкой, аналитическими замечаниями и практическими примерами. Материал базируется на конспектах и дополняется ссылками на нормативные документы и современные исследования.

\subsection{Подтема 1: Представление и кодирование текстовых данных}
Представление текста в цифровой форме — фундаментальный вопрос, который влияет на все последующие стадии обработки и хранения. При проектировании системы важно принять решение о стандарте кодирования на раннем этапе. UTF-8 обладает рядом практических преимуществ: обратная совместимость с ASCII, отсутствие проблем с порядком байтов, широкая поддержка в экосистеме Unix/Linux и в веб-стеке. Однако при работе с системами, которые нативно используют UTF-16 (например, некоторые реализации Windows API или Java), требуется учёт разницы в представлениях и аккуратное преобразование.

Рассмотрим несколько практических сценариев и подводных камней:
\begin{itemize}
	\item При агрегировании данных из разных источников (логи, пользовательский ввод, извлечения из PDF/DOCX) может возникать смесь кодировок. Автоматическая детекция кодировки помогает, но надёжнее поддерживать метаданные об исходной кодировке и логировать операции преобразования.
	\item Нормализация Unicode необходима для доведения семантически равных строк к единой форме — это особенно важно для систем поиска, индексации и для дедупликации документов.
	\item Некоторые старые форматы и протоколы могут сохранять управляющие символы или специфические табличные представления: при конвертации следует учитывать сохранение управляющих последовательностей или их удаление в соответствии с политикой обработки данных.
\end{itemize}

Эти соображения должны быть оформлены в виде руководства по кодировкам внутри проектной документации, которое определяет форматы входных и выходных данных, требования к логированию, и политику нормализации.

\subsection{Подтема 2: Проприетарные и открытые форматы}
Выбор между проприетарными и открытыми форматами зависит от задач, но с точки зрения долговременного хранения открытые стандарты имеют явное преимущество. В организациях, где ценится автономность и доступность в долгосрочной перспективе, целесообразно закладывать в политику требование наличия экспортируемых открытых форматов (ODF, PDF/A, XML) для всех критичных документов.

Практический пример: переход государственного органа на работу с электронными документами. При отсутствии политики использования открытых форматов через 10--15 лет может возникнуть ситуация, когда имеющиеся архивы будут трудно читаемы без дорогостоящих конвертеров. Поэтому политика должна предусматривать создание AIP и хранение исходных файлов вместе с их конвертированными архивационными версиями.

Рабочие рекомендации:
\begin{itemize}
	\item Для рабочих документов — использовать форматы, удобные для редактирования (DOCX, ODF), но при переходе в архив — мигрировать в PDF/A и сохранять исходник.
	\item При интеграции внешних поставщиков требовать, чтобы по результатам передачи данных поставлялся сопроводительный пакет метаданных и описание форматов.
\end{itemize}

\subsection{Подтема 3: Языки разметки}
Языки разметки дают разработчикам и редакторам мощный инструмент для структурирования документов. Markdown удобен для совместной работы и для репозиториев исходников, тогда как LaTeX обеспечивает контроль над типографикой и подходит для конечных форм публикаций.

В практических системах целесообразно использовать концепцию «единый источник истины»: хранить исходный текст в структурированном виде (Markdown или XML), а затем автоматизированно генерировать в различные представления (HTML, PDF, ePub). Такой подход значительно упрощает поддержку версий и распространение контента.

Пример автоматизации: использование панелей CI для построения PDF/HTML из Markdown при каждом обновлении репозитория, что обеспечит воспроизводимость и возможность быстрого отката при ошибках.

\subsection{Подтема 4: Семантическая организация и метаданные}
Семантическая организация повышает ценность документов: метаданные упрощают поиск, каталогизацию и ретроспективный анализ. Dublin Core — удобный и широко применимый набор полей, но для сложных объектов иногда требуется расширение схемы (Qualified Dublin Core или профиль METS/EPUB/TEI для научных текстов).

По опыту архивных практик, наиболее полезными метаданными являются: автор, дата создания и модификации, язык, идентификатор, права и администрационные записи о процессах миграции. Наличие полного журнала операций (audit trail) критично для воспроизводимости и доверия к архиву.

\subsection{Подтема 5: Автоматическая обработка текста}
Автоматизация анализа текстов — быстроразвивающаяся область. Инструменты на основе трансформеров стали де-факто стандартом для задач NER, классификации, суммаризации и семантического поиска. Однако внедрение таких технологий требует внимания к инфраструктуре: потребуются вычислительные ресурсы для обучения/тонкой настройки и процессы для мониторинга деградации качества моделей в боевом окружении.

Рекомендации по внедрению:
\begin{itemize}
	\item Начинать с предобученных моделей и небольших пилотных проектов.
	\item Обеспечить пайплайн для сбора обратной связи и метрик качества в продакшене.
	\item Сохранять версии моделей и датасетов для воспроизводимости.
\end{itemize}

\subsection{Подтема 6: Долговременное хранение — практические кейсы}
Организации различаются по уровню ресурсов и требованиям к сохранности. Малые организации могут полагаться на простую стратегию миграции и репликации, тогда как крупные архифы инвестируют в эмуляцию и сложные системы управления метаданными.

Кейс: Университетская цифровая библиотека. Стратегия может включать приём материалов в виде SIP (включая оригинальные файлы и метаданные), автоматическую валидацию форматов, создание AIP в формате PDF/A или XML и хранение реплик на распределённой системе. Периодические проверки целостности и тестовые восстановление обеспечивают уверенность в сохранности.

В заключение этого раздела: каждая из подтем требует простого, но формализованного набора политик и процедур. Документальные политики и автоматизация процессов — ключ к тому, чтобы сегодняшние данные оставались доступными завтра.

\section{Заключение}
Подведены итоги: для большинства практических задач рекомендуется использовать UTF-8 для хранения текстов, открытые форматы (PDF/A или XML/ODF) для архивирования, а для анализа — современные трансформерные модели и гибридные подходы. Соблюдение практик метаданных и контроля целостности критично для долговременной сохраняемости.

\subsection{Рекомендации по репликации и политике хранения}
Практические принципы для надёжного хранения:
\begin{itemize}
	\item Стратегия 3-2-1: минимум три копии, два типа носителей, одна удалённая копия.
	\item Поддерживать журнал операций (ingest, migration, audit) и хранить его вместе с AIP.
	\item Планировать регулярные проверки целостности и пробные восстановление из копий.
\end{itemize}

\appendix
\section{Приложение A. Инструкция по компиляции}
Документ использует `biblatex` с бэкендом `biber`, поэтому последовательность команд для сборки в среде Windows (PowerShell) примерно следующая:
\begin{verbatim}
pdflatex report.tex
biber report
pdflatex report.tex
pdflatex report.tex
\end{verbatim}
Если вы используете TeX Live или MikTeX, убедитесь что установлены пакеты `biber`, `biblatex`, и языковые пакеты (русский `babel`, `fontenc` для T2A).

\section{Приложение B. Глоссарий и чек-лист}
\begin{itemize}
	\item UTF-8: кодировка Unicode с переменной длиной байтов.
	\item PDF/A: профиль PDF для долговременного хранения.
	\item AIP/SIP/DIP: пакеты согласно модели OAIS.
	\item Fixity: контроль целостности файлов через хеши.
\end{itemize}

\section{Приложение C. Скрипты и примеры автоматизации}
\subsection{PowerShell: пакетная конвертация DOCX → PDF + проверка хеша}
\begin{verbatim}
# Параметры
$sourceDir = "C:\\path\\to\\docx"
$outDir = "C:\\path\\to\\out"
$logFile = "C:\\path\\to\\out\\conversion.log"

Get-ChildItem -Path $sourceDir -Filter *.docx -Recurse | ForEach-Object {
		$in = $_.FullName
		$base = [System.IO.Path]::GetFileNameWithoutExtension($in)
		$out = Join-Path $outDir ($base + ".pdf")
		Write-Output "Converting $in -> $out" | Tee-Object -FilePath $logFile -Append
		soffice --headless --convert-to pdf:writer_pdf_Export --outdir $outDir $in
		$hash = (Get-FileHash -Algorithm SHA256 $out).Hash
		"$base.pdf : $hash" | Tee-Object -FilePath $logFile -Append
}
\end{verbatim}

\subsection{Bash: пакетная конвертация (Linux) + валидация PDF/A}
\begin{verbatim}
#!/bin/bash
SRC_DIR="/path/to/docx"
OUT_DIR="/path/to/out"
mkdir -p "$OUT_DIR"
for f in "$SRC_DIR"/*.docx; do
	echo "Converting $f"
	libreoffice --headless --convert-to pdf:writer_pdf_Export --outdir "$OUT_DIR" "$f"
	# Пример валидации (verapdf должен быть установлен)
	pdfname=$(basename "$f" .docx).pdf
	verapdf --flavour 1b "$OUT_DIR/$pdfname" > "$OUT_DIR/$pdfname-verification.txt"
done
\end{verbatim}

\subsection{Примечания по использованию скриптов}
\begin{itemize}
	\item Убедитесь, что LibreOffice/soffice доступен в PATH.
	\item Для валидации PDF/A используйте `verapdf` или коммерческие валидаторы.
	\item Логи должны храниться рядом с AIP и вноситься в метаданные пакета.
\end{itemize}

\section{Приложение D. Чек-лист архивации}
Ниже приведён чек-лист, который можно применять при приёме документов в архив.
\begin{enumerate}
	\item Инвентаризация: заполнить таблицу с метаданными (идентификатор, автор, дата, формат, размер).
	\item Контроль целостности: вычислить SHA-256 для каждого файла и сохранить значения.
	\item Конвертация: при необходимости сконвертировать в PDF/A и сохранить оригинал.
	\item Валидация: проверить соответствие PDF/A, проверить шрифты и встраивание.
	\item Создание AIP: собрать файл, метаданные и лог в архивационный пакет.
	\item Репликация: разместить не менее двух реплик в разных локациях.
	\item Документация: записать журнал операций (ingest, migration, audit).
\end{enumerate}

\section{Приложение E. Дополнительные таблицы и иллюстрации-заглушки}
\subsection{Таблица: Сравнение форматов по критериям}
\begin{table}[H]
\centering
\begin{tabular}{p{3.5cm} p{2.5cm} p{2.5cm} p{3.5cm}}
Формат & Открытый? & Поддержка метаданных & Примечания \\
\hline
TXT/CSV & Да & Нет (встроенно) & Хорош для данных и логов \\
PDF/A & Частично (стандарт ISO) & Да (XMP) & Идеален для архивации \\
DOCX & Частично & Да (Open XML properties) & Богатый функционал, риск зависимости \\
ODF & Да & Да & Открытый формат офисных документов \\
\end{tabular}
\caption{Сравнение форматов по критериям}
\end{table}

\subsection{Развёрнутые практические кейсы и примеры}
В этом разделе приведены подробные практические кейсы внедрения систем хранения и обработки текстовых документов, шаблоны политик и примеры логов, которые помогут внедрить предложенные подходы на практике.

\subsubsection{Кейс 1 — Государственный реестр документов}
Организация: ведомство государственного управления, объём входящих документов — десятки тысяч в год. Требования: долговременное хранение юридически значимых документов, обеспечение целостности и аудита.

Решение: при приёме документов формируется SIP, содержащий оригинал, PDF/A-версию, полный набор метаданных Dublin Core, а также JSON-файл с техническими метаданными о процессе приёма (время, оператор, инструмент конвертации). AIP формируется автоматически и реплицируется на три независимые площадки (локальная, удалённая и облачная).

Ключевые моменты реализации:
\begin{itemize}
	\item Обязательное встраивание всех шрифтов в PDF/A и контроль верификации через `verapdf`.
	\item Вычисление SHA-256 для каждого файла и хранение значений в защищённой базе метаданных.
	\item Журнал операций (audit trail) с неизменяемым хранением (например, WORM-накопители либо блокчейн-подобная запись для критичных объектов).
\end{itemize}

\subsubsection{Кейс 2 — Университетская библиотека}
Задача: оцифровка рукописей и обеспечение доступа исследователям. Проблемы: неоднородные форматы, необходимость хранения высококачественных изображений и текстов, обеспечение полнотекстового поиска.

Решение: исходные отсканы хранятся в TIFF (архив), для доступа генерируются PDF/A и OCR-тексты. Метаданные оформляются согласно Dublin Core + локальные поля (subject headings). Тематические коллекции индексируются для быстрого поиска и тематического анализа.

Практические советы:
\begin{itemize}
	\item Хранить оригинальные файлы (bitstream) отдельно от предоставляемых версий (DIP).
	\item Для больших коллекций применять тематическое индексирование и создания пакетных LDA-моделей для навигации по тематикам.
\end{itemize}

\subsection{Шаблон политики миграции и чек-лист выполнения миграции}
Ниже представлен минимальный шаблон политики миграции и детализированный чек-лист шагов на случай массовой конверсии.

\subsubsection{Политика миграции (минимум)}
\begin{enumerate}
	\item Цель: обеспечение доступа к цифровым объектам на период не менее 50 лет.
	\item Область применения: все электронные документы, поступающие в архив.
	\item Целевые форматы: PDF/A-2 (B/A), XML для структурированных данных, UTF-8 для текстов.
	\item Процедура проверки: визуальная и автоматическая валидация после каждой миграции; сохранение оригинального битового образа.
	\item Ответственность: назначить ответственных за миграцию и аудит.
\end{enumerate}

\subsubsection{Чек-лист процедур миграции}
\begin{enumerate}
	\item Подготовка: инвентаризация, резервные копии исходных данных.
	\item Автоматическая конвертация по партиям с логированием ошибок.
	\item Автоматическая валидация (hash, PDF/A-проверка, сравнение метаданных).
	\item Сравнение визуального сходства (выборочная проверка).
	\item Фиксация результатов и интеграция в AIP.
\end{enumerate}

\subsection{Примеры реальных логов и метаданных}
Ниже — пример записи лога процесса инжеста и пример расширенного блока метаданных в XML/JSON.

\subsubsection{Пример строки лога (ingest)}
\begin{verbatim}
2025-11-13T10:34:12Z INFO ingest: received file=contract_2025_001.docx size=258912 bytes
2025-11-13T10:34:12Z INFO ingest: detected_encoding=UTF-8
2025-11-13T10:34:45Z INFO convert: created contract_2025_001.pdf (PDF/A)
2025-11-13T10:34:46Z INFO fixity: sha256=3a7bd3... stored
2025-11-13T10:34:46Z INFO aip: package created id=aip:2025:0001
\end{verbatim}

\subsubsection{Пример расширенного блока метаданных (JSON)}
\begin{verbatim}
{
	"id": "aip:2025:0001",
	"title": "Договор №1",
	"creator": "Отдел закупок",
	"created": "2025-10-28",
	"format": "application/pdf",
	"fixity": {
		"sha256": "3a7bd3...",
		"date": "2025-11-13T10:34:46Z"
	},
	"ingest_log": [ ... ]
}
\end{verbatim}

\subsection{Метрики и аудит качества архива}
Для оценки качества архива рекомендуется применять набор метрик: процент успешно конвертированных файлов, процент ошибок валидации, среднее время инжеста, частота обнаруженной порчи (fixity failures) и показатели доступности реплик.

\subsection{План расширенной проверки целостности}
Рекомендуемая периодичность проверок: полный аудит контрольных сумм — раз в год, выборочные проверки — ежемесячно (10% от объёма). При обнаружении расхождений — автоматическая процедура восстановления из ближайшей неповреждённой реплики и регистрация инцидента.

\subsection{Шаблон уведомления о фиксации ошибок}
\begin{verbatim}
To: archive-admin@example.org
Subject: [ALERT] Fixity failure detected for object aip:2024:0123

Details:
	Object: aip:2024:0123
	File: document.pdf
	Original SHA256: 9f8a...
	Current SHA256: 1b2c...
	Detected: 2025-11-13T11:05:07Z

Action: initiate recovery from replica storage and log incident.
\end{verbatim}

\medskip
-- Конец расширённых материалов --

\printbibliography

\end{document}

\printbibliography

\end{document}
